{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "926b642b-5979-4689-a09d-6acd9cce6058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used is:  cuda:0\n",
      "torch_dtype is:  torch.float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of WhisperForConditionalGeneration were not initialized from the model checkpoint at openai/whisper-large-v3 and are newly initialized: ['proj_out.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong index found for <|0.02|>: should be None but found 50366.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSpeechSeq2Seq\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     18\u001b[0m     model_id, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, low_cpu_mem_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, use_safetensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m processor \u001b[38;5;241m=\u001b[39m \u001b[43mAutoProcessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautomatic-speech-recognition\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecord_chunk\u001b[39m(p, stream, chunk_file):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py:273\u001b[0m, in \u001b[0;36mAutoProcessor.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m processor_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    270\u001b[0m         pretrained_model_name_or_path, trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    271\u001b[0m     )\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m processor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprocessor_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m# Last try: we use the PROCESSOR_MAPPING.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m PROCESSOR_MAPPING:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/processing_utils.py:215\u001b[0m, in \u001b[0;36mProcessorMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# change to `token` in a follow-up PR\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_auth_token\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m--> 215\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_arguments_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/processing_utils.py:259\u001b[0m, in \u001b[0;36mProcessorMixin._get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m         attribute_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(transformers_module, class_name)\n\u001b[0;32m--> 259\u001b[0m     args\u001b[38;5;241m.\u001b[39mappend(\u001b[43mattribute_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1841\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1838\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1839\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from cache at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_vocab_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_configuration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minit_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1851\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1852\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2053\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, use_auth_token, cache_dir, local_files_only, _commit_hash, _is_local, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2049\u001b[0m current_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokenizer) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(tokens)\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_tokenizer_file \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m current_index \u001b[38;5;129;01mand\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(token) \u001b[38;5;241m!=\u001b[39m index:\n\u001b[1;32m   2051\u001b[0m     \u001b[38;5;66;03m# Tokenizer fast: added token needs to either be in the vocabulary with the proper index or the\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;66;03m# index is the current length of the tokenizer (not in vocabulary)\u001b[39;00m\n\u001b[0;32m-> 2053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2054\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong index found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: should be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(token)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2055\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2056\u001b[0m     )\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_tokenizer_file \u001b[38;5;129;01mand\u001b[39;00m index \u001b[38;5;241m!=\u001b[39m current_index:\n\u001b[1;32m   2058\u001b[0m     \u001b[38;5;66;03m# Tokenizer slow: added token cannot already be in the vocabulary so its index needs to be the\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m     \u001b[38;5;66;03m# current length of the tokenizer.\u001b[39;00m\n\u001b[1;32m   2060\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2061\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-consecutive added token \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoken\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m found. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2062\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but has index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in saved vocabulary.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2063\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong index found for <|0.02|>: should be None but found 50366."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import pyaudio\n",
    "import wave\n",
    "from pytube import YouTube, Playlist\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Device used is: ',device)\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "print('torch_dtype is: ',torch_dtype)\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to('cuda')\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "def record_chunk(p, stream, chunk_file):\n",
    "    frames = []\n",
    "    for i in range(0,int(rate/chunk*2)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    wf = wave.open(chunk_file,'wb')\n",
    "    wf.setnchannels(channel) \n",
    "    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))\n",
    "    wf.setframerate(rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "\n",
    "inp = input('Enter 1 for microphone and 2 for youtube audio')\n",
    "if(inp==1):\n",
    "    final_text = ''\n",
    "    p = pyaudio.PyAudio()\n",
    "    chunk = 1024\n",
    "    channel = 1\n",
    "    rate = 50000\n",
    "    stream = p.open(format=pyaudio.paInt16, \n",
    "                    channels=channel, \n",
    "                    rate=rate, \n",
    "                    input=True, \n",
    "                    frames_per_buffer=chunk)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            chunk_file = 'hello.mp3'\n",
    "            record_chunk(p,stream,chunk_file)\n",
    "            result = pipe(\"hello.mp3\",generate_kwargs={\"task\": \"translate\"})\n",
    "            print(result)\n",
    "            final_text+=result['text']\n",
    "    except Exception as e:\n",
    "        print(\"Done\",e)\n",
    "    finally:\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "        print(final_text)\n",
    "else:\n",
    "    yt = YouTube(\"https://www.youtube.com/watch?v=4KI9BBW_aP8\")\n",
    "    \n",
    "    # yt = YouTube(\"https://www.youtube.com/watch?v=dd1kN_myNDs\")\n",
    "    stream = yt.streams.filter(only_audio=True)[0]\n",
    "    stream.download(filename=\"audio_english2.mp3\")\n",
    "    result = pipe(\"audio_english2.mp3\",generate_kwargs={\"task\": \"translate\"})\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
